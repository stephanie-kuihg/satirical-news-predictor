{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pre-processing and Modelling\n",
    "\n",
    "## Overview<a class=\"anchor\" id=\"overview\"></a>\n",
    "---\n",
    "This section will pre-process and model using the cleaned datasets. Estimators selected for modelling are Multinomial Naive Bayes and Logistic Regression. <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents <a class=\"anchor\" id=\"toc\"></a>\n",
    "---\n",
    "\n",
    "* [Overview](#overview)\n",
    "* [Importing Libraries](#importinglibraries)\n",
    "* [Creating Custom Functions](#customfunctions)\n",
    "* [Pre-processing for Modelling](#preprocessing)\n",
    "* [Modelling & Evaluation](#modelevaluation)\n",
    "    * [Naive Bayes](#naivebayes)\n",
    "        * [Model NB_1.1](#nb_1.1)\n",
    "        * [Model NB_1.2](#nb_1.2)\n",
    "        * [Model NB_1.3](#nb_1.3)\n",
    "        * [Model NB_1.4](#nb_1.4)\n",
    "        * [Summary](#nb_summary)\n",
    "    * [Logistic Regression](#logreg)\n",
    "        * [Model LR_2.1](#lr_2.1)\n",
    "        * [Model LR_2.2](#lr_2.2)\n",
    "        * [Model LR_2.3](#lr_2.3)\n",
    "        * [Model LR_2.4](#lr_2.4)\n",
    "        * [Summary](#lr_summary)\n",
    "    * [Comparison of scores across all models](#comparison)\n",
    "* [Conclusions & Future Development](#conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries <a class=\"anchor\" id=\"importinglibraries\"></a>\n",
    "---\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, plot_roc_curve\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Functions <a class=\"anchor\" id=\"customfunctions\"></a>\n",
    "---\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model_name, pipeline):\n",
    "    print(model_name)\n",
    "    print('------------')\n",
    "    train_score = pipeline.score(X_train, y_train)\n",
    "    print(f'Training score: {round(train_score, 4)}')\n",
    "    test_score = pipeline.score(X_test, y_test)\n",
    "    print(f'Testing score: {round(test_score, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "def get_evaluation_metrics(model_name, cm, preds):\n",
    "    print(model_name)\n",
    "    print('------------')\n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    print(\"True Positives: %s\" % tp)\n",
    "    print()\n",
    "    \n",
    "    # accuracy = (tn + tp) / (tn + fp + fn + tp) \n",
    "    accuracy = accuracy_score(y_test, preds) \n",
    "    print(f'Accuracy: {round(accuracy, 4)}')\n",
    "    \n",
    "    specificity = tn / (tn + fp)\n",
    "    print(f'Specificity: {round(specificity, 4)}')\n",
    "    \n",
    "    # sensitivity = tp / (tp + fn)\n",
    "    sensitivity = recall_score(y_test, preds)\n",
    "    print(f'Sensitivity: {round(sensitivity, 4)}')\n",
    "    \n",
    "    # precision = tp / (tp + fp)\n",
    "    precision = precision_score(y_test, preds)\n",
    "    print(f'Precision: {round(precision, 4)}')\n",
    "    \n",
    "    # f1score = 2 * (precision*sensitivity) / (precision + sensitivity)\n",
    "    f1score = f1_score(y_test, preds)\n",
    "    print(f'F1 score: {round(f1score, 4)}')\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, preds)\n",
    "    print(f'ROC AUC score: {round(roc_auc, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gs_metrics(model_name, gs_model):\n",
    "    print(model_name)\n",
    "    print('------------')\n",
    "    # best params\n",
    "    best_params = gs_model.best_params_\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    # best score\n",
    "    best_score = gs_model.best_score_\n",
    "    print(f\"Best train score: {round(best_score, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing for Modelling <a class=\"anchor\" id=\"preprocessing\"></a>\n",
    "---\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Representative Wants To Meet More Kids Online</td>\n",
       "      <td>TheOnion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Minnesota Deploys National Guard Ahead Of Next...</td>\n",
       "      <td>TheOnion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Small Kindnesses: Gamer Shields Ailing Grandmo...</td>\n",
       "      <td>TheOnion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Report: San Diegans Just Assumed Padres Were I...</td>\n",
       "      <td>TheOnion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colorado Temporarily Re-Bans Marijuana For Sta...</td>\n",
       "      <td>TheOnion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title subreddit\n",
       "0      Representative Wants To Meet More Kids Online  TheOnion\n",
       "1  Minnesota Deploys National Guard Ahead Of Next...  TheOnion\n",
       "2  Small Kindnesses: Gamer Shields Ailing Grandmo...  TheOnion\n",
       "3  Report: San Diegans Just Assumed Padres Were I...  TheOnion\n",
       "4  Colorado Temporarily Re-Bans Marijuana For Sta...  TheOnion"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satire = pd.read_csv('../data/modelling_dataset.csv')\n",
    "satire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Representative Wants To Meet More Kids Online</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Minnesota Deploys National Guard Ahead Of Next...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Small Kindnesses: Gamer Shields Ailing Grandmo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Report: San Diegans Just Assumed Padres Were I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colorado Temporarily Re-Bans Marijuana For Sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  subreddit\n",
       "0      Representative Wants To Meet More Kids Online          1\n",
       "1  Minnesota Deploys National Guard Ahead Of Next...          1\n",
       "2  Small Kindnesses: Gamer Shields Ailing Grandmo...          1\n",
       "3  Report: San Diegans Just Assumed Padres Were I...          1\n",
       "4  Colorado Temporarily Re-Bans Marijuana For Sta...          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satire['subreddit'] = satire['subreddit'].map({'TheOnion': 1, 'worldnews': 0})\n",
    "satire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>Tim Hortons, Metro among retailers in new repo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>Covid Philippines: Man dies after being forced...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>Lightning strikes will more than double in Arc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4202</th>\n",
       "      <td>As it battles its worst drought in 56 years, T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>Iran indicts 10 officials over shootdown of Uk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  subreddit\n",
       "4199  Tim Hortons, Metro among retailers in new repo...          0\n",
       "4200  Covid Philippines: Man dies after being forced...          0\n",
       "4201  Lightning strikes will more than double in Arc...          0\n",
       "4202  As it battles its worst drought in 56 years, T...          0\n",
       "4203  Iran indicts 10 officials over shootdown of Uk...          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satire.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = satire['title']\n",
    "y = satire['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.556851\n",
       "0    0.443149\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking balance of classes\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5804\n",
       "0    0.4196\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline accuracy\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>cvec</th>\n",
       "      <th>tvec</th>\n",
       "      <th>gs</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Null Model</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  cvec  tvec  gs  Train Score  Test Score  Precision  \\\n",
       "0  Null Model     0     0   0          NaN      0.5804        NaN   \n",
       "\n",
       "   Specificity  Recall  F1 Score  ROC AUC Score  \n",
       "0          NaN     NaN       NaN            NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of dict\n",
    "dict_null = [{'Model': 'Null Model', \n",
    "            'cvec': 0, 'tvec': 0, 'gs': 0,\n",
    "            'Train Score': np.nan, \n",
    "            'Test Score': 0.5804,\n",
    "            'Precision': np.nan, \n",
    "            'Specificity': np.nan,\n",
    "            'Recall': np.nan,\n",
    "            'F1 Score': np.nan, \n",
    "            'ROC AUC Score': np.nan}\n",
    "           ]\n",
    "\n",
    "df_null = pd.DataFrame(dict_null)\n",
    "df_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling & Evaluation <a class=\"anchor\" id=\"modelevaluation\"></a>\n",
    "---\n",
    "[Back to top!](#toc)\n",
    "\n",
    "The modelling workflow will be as such:\n",
    "1. Using a transformer of choice (in this case Count Vectorizer then TD-IDF Vectorizer) to transform the dataframe\n",
    "2. Using an estimator of choice (in this case Multinomial Naive Bayes then Logistic Regression) to train the model\n",
    "3. Evaluate the model based on metrics such as `Train Score`, `Test Score`, `Precision`, `Specificity`, `Recall`, `ROC AUC Score` and the confusion matrix.\n",
    "4. Using GridSearchCV to find the best hyperparameters for fine-tuning the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naïve Bayes <a class=\"anchor\" id=\"naivebayes\"></a>\n",
    "---\n",
    "[Back to top!](#toc)\n",
    "\n",
    "A total of 4 models will be trained using Multinomial Naive Bayes as an estimator:\n",
    "* Model NB_1.1 - Using CountVectorizer and Multinomial Naive Bayes\n",
    "* Model NB_1.2 - Optimizing Model NB_1.1 using GridSearchCV\n",
    "* Model NB_1.3 - Using TF-IDF Vectorizer and Multinomial Naive Bayes\n",
    "* Model NB_1.4 - Optimizing Model_1.3 using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model NB_1.1 - Using CountVectorizer and Multinomial Naive Bayes <a class=\"anchor\" id=\"nb_1.1\"></a>\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec',\n",
       "   CountVectorizer(stop_words=('english', 'onion', 'topical', 'ho'))),\n",
       "  ('nb', MultinomialNB())],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(stop_words=('english', 'onion', 'topical', 'ho')),\n",
       " 'nb': MultinomialNB(),\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': ('english', 'onion', 'topical', 'ho'),\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': None,\n",
       " 'cvec__vocabulary': None,\n",
       " 'nb__alpha': 1.0,\n",
       " 'nb__class_prior': None,\n",
       " 'nb__fit_prior': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redefining training and testing sets with same random_state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Setting up pipeline for model 1.1\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "pipe_11 = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=('english', 'onion', 'topical', 'ho'))),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fitting the pipeline\n",
    "pipe_11.fit(X_train, y_train)\n",
    "pipe_11.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NB_1.1\n",
      "------------\n",
      "Training score: 0.9772\n",
      "Testing score: 0.9039\n"
     ]
    }
   ],
   "source": [
    "get_scores('Model NB_1.1', pipe_11)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "train_score_11 = pipe_11.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NB_1.1\n",
      "------------\n",
      "True Negatives: 400\n",
      "False Positives: 41\n",
      "False Negatives: 60\n",
      "True Positives: 550\n",
      "\n",
      "Accuracy: 0.9039\n",
      "Specificity: 0.907\n",
      "Sensitivity: 0.9016\n",
      "Precision: 0.9306\n",
      "F1 score: 0.9159\n",
      "ROC AUC score: 0.9043\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds_11 = pipe_11.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_11).ravel()\n",
    "cm_11 = tn, fp, fn, tp \n",
    "get_evaluation_metrics('Model NB_1.1', cm_11, preds_11)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "spec_11 = tn / (tn + fp)\n",
    "\n",
    "# visualizing confusion matrix\n",
    "plot_confusion_matrix(pipe_11, X_test, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model NB_1.2 - Optimizing Model NB_1.1 using GridSearchCV <a class=\"anchor\" id=\"nb_1.2\"></a>\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# Minimum number of documents needed to include token: 2, 3\n",
    "# Maximum number of documents needed to include token: 90%, 95%\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words=('english',\n",
       "                                                                    'onion',\n",
       "                                                                    'topical',\n",
       "                                                                    'ho'))),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "cvec_gs = GridSearchCV(pipe_11, # what object are we optimizing?\n",
    "                       param_grid=pipe_params, # what parameters values are we searching?\n",
    "                       cv=5) # 5-fold cross-validation.\n",
    "\n",
    "# Fit GridSearch to training data.\n",
    "cvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NB_1.2\n",
      "------------\n",
      "Best Parameters: {'cvec__max_df': 0.9, 'cvec__max_features': 4000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1)}\n",
      "Best train score: 0.901\n"
     ]
    }
   ],
   "source": [
    "get_gs_metrics('Model NB_1.2', cvec_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NB_1.2\n",
      "------------\n",
      "Training score: 0.9588\n",
      "Testing score: 0.8906\n"
     ]
    }
   ],
   "source": [
    "get_scores('Model NB_1.2', cvec_gs)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "train_score_12 = cvec_gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NB_1.2\n",
      "------------\n",
      "True Negatives: 394\n",
      "False Positives: 47\n",
      "False Negatives: 68\n",
      "True Positives: 542\n",
      "\n",
      "Accuracy: 0.8906\n",
      "Specificity: 0.8934\n",
      "Sensitivity: 0.8885\n",
      "Precision: 0.9202\n",
      "F1 score: 0.9041\n",
      "ROC AUC score: 0.891\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds_12 = cvec_gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_12).ravel()\n",
    "cm_12 = tn, fp, fn, tp \n",
    "get_evaluation_metrics('Model NB_1.2', cm_12, preds_12)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "spec_12 = tn / (tn + fp)\n",
    "\n",
    "# visualizing confusion matrix\n",
    "plot_confusion_matrix(cvec_gs, X_test, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model NB_1.3 - Using TF-IDF Vectorizer and Multinomial Naive Bayes <a class=\"anchor\" id=\"nb_1.3\"></a>\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tvec',\n",
       "   TfidfVectorizer(stop_words=('english', 'onion', 'topical', 'ho'))),\n",
       "  ('nb', MultinomialNB())],\n",
       " 'verbose': False,\n",
       " 'tvec': TfidfVectorizer(stop_words=('english', 'onion', 'topical', 'ho')),\n",
       " 'nb': MultinomialNB(),\n",
       " 'tvec__analyzer': 'word',\n",
       " 'tvec__binary': False,\n",
       " 'tvec__decode_error': 'strict',\n",
       " 'tvec__dtype': numpy.float64,\n",
       " 'tvec__encoding': 'utf-8',\n",
       " 'tvec__input': 'content',\n",
       " 'tvec__lowercase': True,\n",
       " 'tvec__max_df': 1.0,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__norm': 'l2',\n",
       " 'tvec__preprocessor': None,\n",
       " 'tvec__smooth_idf': True,\n",
       " 'tvec__stop_words': ('english', 'onion', 'topical', 'ho'),\n",
       " 'tvec__strip_accents': None,\n",
       " 'tvec__sublinear_tf': False,\n",
       " 'tvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tvec__tokenizer': None,\n",
       " 'tvec__use_idf': True,\n",
       " 'tvec__vocabulary': None,\n",
       " 'nb__alpha': 1.0,\n",
       " 'nb__class_prior': None,\n",
       " 'nb__fit_prior': True}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redefining training and testing sets with same random_state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Setting up pipeline for model 1.3\n",
    "# 1. TD-IDF Vectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "pipe_13 = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(stop_words=('english', 'onion', 'topical', 'ho'))),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fitting the pipeline\n",
    "pipe_13.fit(X_train, y_train)\n",
    "pipe_13.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NB_1.3\n",
      "------------\n",
      "Training score: 0.9753\n",
      "Testing score: 0.8991\n"
     ]
    }
   ],
   "source": [
    "get_scores('Model NB_1.3', pipe_13)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "train_score_13 = pipe_13.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NB_1.3\n",
      "------------\n",
      "True Negatives: 380\n",
      "False Positives: 61\n",
      "False Negatives: 45\n",
      "True Positives: 565\n",
      "\n",
      "Accuracy: 0.8991\n",
      "Specificity: 0.8617\n",
      "Sensitivity: 0.9262\n",
      "Precision: 0.9026\n",
      "F1 score: 0.9142\n",
      "ROC AUC score: 0.894\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEGCAYAAADxD4m3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAab0lEQVR4nO3de7xd453H8c/3nFyQhNwjIiFIELfQMCXq2qloR+lFJ6ozeVXa1G2YMm0xHVpt1HTa0qGGFG2UihhUinGZjAgzikQRQSSEiETiRIIESc45v/ljr8OW5uyzV3J29l7rfN9e+3X2Xntdfid55et51lrPsxQRmJnlUV21CzAzqxQHnJnllgPOzHLLAWdmueWAM7Pc6lTtAop17tYztuq9fbXLsBR269+92iVYCotefYUVDQ3anH3Ub7tTROP7Za0b7795X0SM2ZzjbY6aCritem/P/t++ttplWAp3nX5ItUuwFA4ffdBm7yMa36fr7l8pa90PnvpV380+4GaoqYAzsywQKBtntxxwZpaOgLr6aldRFgecmaWnzTqNt8U44MwsJXdRzSzP3IIzs1wSbsGZWV7JLTgzyzFfRTWzfPJFBjPLK+EuqpnlmFtwZpZP7qKaWV4JqPdFBjPLK5+DM7N8chfVzPLMLTgzyy234Mwsl+ShWmaWZx6qZWb55IsMZpZn7qKaWS5laD64bFRpZjUk6aKW82prT9IrkuZIekrSrGRZb0kPSJqf/OxVtP75khZImifpmLb274Azs/Tq6st7lefIiBgZEaOSz+cB0yNiGDA9+YykEcBYYC9gDHCVpJIHccCZWXott4q09do0xwOTk/eTgROKlk+JiLURsRBYAJR8krUDzszSUft1UYEA7pc0W9KEZNmAiFgKkPzsnywfBLxWtO3iZFmrfJHBzNIrv3XWt+XcWmJSREwq+jw6IpZI6g88IOmFUkfdyLIodXAHnJmlpvIDrqHo3NpfiIglyc/lku6g0OVcJmlgRCyVNBBYnqy+GBhctPmOwJJSB3cX1cxSKcxYrrJeJfcjdZPUo+U98BngWWAaMC5ZbRxwZ/J+GjBWUldJQ4FhwOOljuEWnJmlI6G6drnRdwBwRxKEnYDfR8S9kp4ApkoaDywCTgSIiLmSpgLPAY3AGRHRVOoADjgzSy1FF7VVEfEysN9Glq8Ajm5lm4nAxHKP4YAzs9TaI+C2BAecmaXmgDOzfBIbv2GjBjngzCwV0fYV0lrhgDOz1OrqsnGHmQPOzFJzC87M8snn4Mwsz9yCM7Nc8kUGM8u1dhqqVXEOODNLR+6imlmOOeDMLLcccGaWS77IYGb5lo18c8CZWUryUC0zyzF3Uc0sv7KRbw64zdW5Xvz8S/vSub6O+jp4eMEKfvfYInbp242zj9qVLvV1NDUHV8x4iXnLVgMwdtSOHDNiAM0RXPXQy8xetKq6v0QH9/a773HOT27mhZeWIonL/vmrLF2+ip9d91+8+Moy7r3uXEbuOaTaZdYUt+AASWOAXwL1wLURcWklj1cN65uC794xhw/WN1NfJy778r488epKxn1yCDc+9hpPvLqSA3fqxTdGD+U7t89hSO+tOXxYPybc9CR9unXh0i/szSk3zKa55NMdrZK+f9ntHPnJPbnukvGsW9/I+x+sY7seW3P9T8bznX+9pdrl1ZxynphVKyp2plBSPfAr4FhgBHCSpBGVOl41fbC+GYBOdaK+ThBBBGzTpR6Abl3rWbFmLQCH7NKHh+a/yfqm4I131rJk1QfsPqBH1Wrv6N5d8z6PPrWAk487GIAunTuxXY9tGL7z9uy204AqV1e72uOxgVtCJVtwBwELkifnIGkKcDyFR37lSp3gV2NHssN2WzPtmaW8sGw1/zHzZX5ywl5MOHQoEvzjrc8A0KdbF154490Pt21YvZa+3btUq/QO79XXV9CnZ3fO/vFNzJ3/OvvuMZgff/tLdNu6a7VLq2lZGYtayWu9g4DXij4vTpZ9jKQJkmZJmrV+zaoKllM5zQGn3fwUX73+cXbfvjs7996G4/YZyNUzF3Lyb57g6ocXcs7RwwDY2P/Uwt3TqmlsambOi4sZ98VDmX7D99hm665cccN/V7usmpeVFlwlA25jv91f/FOOiEkRMSoiRnXu1rOC5VTemnVNPLP4bUbt1Iu/3rM/j7y0AoCZ8xvYffvuADSsXke/Hh+1Dvp278qKNeuqUq/BDv17skO/nnxir50BOO7Ikcx58bXSG3V0csBBocU2uOjzjsCSCh6vKrbbuhPdknNtXerr2H9wT15b+R4r1qxj30HbATByx+1YsuoDAB59+S0OH9aPzvVi+227Mqjn1sxb9m6r+7fK6t9nW3YY0JMFry4D4OFZ8xi+8/ZVrqq2iUJPpJxXtVXyHNwTwDBJQ4HXgbHAVyt4vKrovU0XvvOZ4dRJ1Akemt/AY6+sZPXaJk4/fBfqJNY3NXP59PkAvPrWe8yc/ya//toBNDUHV854yVdQq+ySc77M6T+4gXXrm9hpUB9++c8nc8+Mp7ngF//JilWrOfnca9h7+CBuufz0apdaI2qjdVYORQVPAEn6LHA5hdtEro+IiaXW7zF4j9j/29dWrB5rf3edfki1S7AUDh99EH+ePWuz0mmr7YfHTuOuKGvdF386ZnZEjNqc422Oit4HFxH3APdU8hhmtoXVSPezHB7JYGapCKjLyG0iDjgzS80tODPLraxcZHDAmVk6PgdnZnkllJkJL7NRpZnVlPa80VdSvaQ/S7or+dxb0gOS5ic/exWte76kBZLmSTqmrX074MwstXYeqnU28HzR5/OA6RExDJiefCaZjWgssBcwBrgqmbWoVQ44M0unzNZbOfkmaUfgc0DxHf7HA5OT95OBE4qWT4mItRGxEFhAYdaiVjngzCyVwljUsltwfVtmC0peEzbY3eXAd4HmomUDImIpQPKzf7K8rBmKivkig5mlluIqakNrQ7Uk/Q2wPCJmSzqinMNuZFnJsaYOODNLrZ1GMowGPp+MWd8K2FbSjcAySQMjYqmkgcDyZP3UMxS5i2pm6bTTfHARcX5E7BgRO1O4ePA/EfE1YBowLlltHHBn8n4aMFZS12SWomHA46WO4RacmaXSMh9cBV0KTJU0HlgEnAgQEXMlTaXw2ING4IyIaCq1IwecmaXU/vPBRcQMYEbyfgVwdCvrTQRKTrtWzAFnZql5qJaZ5ZM8XZKZ5VTLfXBZ4IAzs9QccGaWWxnJNwecmaXnFpyZ5ZMnvDSzvCpMeJmNhHPAmVlqdRlpwjngzCy1jOSbA87M0pF8kcHMciwjp+BaDzhJV1BiMrmIOKsiFZlZzcvDRYZZW6wKM8sMUbiSmgWtBlxETC7+LKlbRKypfElmVusy0oBre0ZfSQdLeo7ksV6S9pN0VcUrM7PaVOZsvrVwIaKcKcsvB44BVgBExNPAYRWsycxqXHs++LmSyrqKGhGvbZDGJacJNrP8Evm60fc1SYcAIakLcBYffwq1mXUwWbmKWk4X9VTgDAoPWH0dGJl8NrMOqNzuaS008tpswUVEA3DyFqjFzDIiK13Ucq6i7iLpj5LelLRc0p2SdtkSxZlZbVKZr2orp4v6e2AqMBDYAbgVuLmSRZlZbcvTbSKKiN9FRGPyupESQ7jMLN8KV1HLe1VbqbGovZO3D0o6D5hCIdj+Frh7C9RmZrVI+ZjwcjaFQGv5Tb5V9F0AP6pUUWZW22qh+1mOUmNRh27JQswsG1q6qFlQ1kgGSXsDI4CtWpZFxA2VKsrMalvmW3AtJF0EHEEh4O4BjgUeARxwZh1UNuKtvKuoXwaOBt6IiK8D+wFdK1qVmdUsCerrVNar2srpor4fEc2SGiVtCywHfKOvWQeWmy4qMEtST+DXFK6srgYer2RRZlbbMpJvZY1FPT15e7Wke4FtI+KZypZlZrVKKDNjUUvd6HtAqe8i4snKlGRmNa2dZgqRtBUwk8I5/U7Af0bERckgg1uAnYFXgK9ExMpkm/OB8RTmpDwrIu4rdYxSLbifl/gugKPK+zXKN7x/d+4/69D23q1VUK8Dz6x2CZbC2nmL2mU/7XQObi1wVESsltQZeETSfwFfBKZHxKXJKKrzgO9JGgGMBfaiMC7+vyUNj4hWJ+AtdaPvke3xG5hZvgiob4eAi4igcE4foHPyCuB4CremAUwGZgDfS5ZPiYi1wEJJC4CDgEdbO0Y5t4mYmX1MisH2fSXNKnpNKN6PpHpJT1G4O+OBiHgMGBARSwGSn/2T1QcBrxVtvjhZ1io/2d7MUktxi1tDRIxq7cukezkyuVPjjmTUVGs2dtSSMxu5BWdmqRSmI2/f+eAiYhWFrugYYJmkgYVjaSCF1h0UWmyDizbbEVhSar/lzOgrSV+TdGHyeYikg8qu3Mxypz3mg5PUL2m5IWlr4NPAC8A0YFyy2jjgzuT9NGCspK6ShgLDaOOe3HK6qFcBzRSuml4MvAvcBhxYxrZmlkPtdBvcQGCypHoKja2pEXGXpEeBqZLGA4uAEwEiYq6kqcBzQCNwRqkrqFBewP1VRBwg6c/JQVYmjw80sw5IQKf2uYr6DLD/RpavoDD+fWPbTAQmlnuMcgJufZKwAYVmJYUWnZl1UBkZyFBWwP07cAfQX9JECrOLfL+iVZlZzZJyMFSrRUTcJGk2hSajgBMiwk+2N+vAMpJvZU14OQR4D/hj8bKIaJ8xH2aWOTUw1VtZyumi3s1HD5/ZChgKzKMwHszMOhhBTUxmWY5yuqj7FH9OZhn5Viurm1ne1cgzT8uReqhWRDwpyffAmXVgyshTGco5B3dO0cc64ADgzYpVZGY1LW+PDexR9L6Rwjm52ypTjpllQS4CLrnBt3tEfGcL1WNmGZD5h85I6hQRjaWmLjezjqfw2MBqV1GeUi24xymcb3tK0jTgVmBNy5cRcXuFazOzGpWbkQxAb2AFhdlEWu6HC8ABZ9YB5eUiQ//kCuqzfBRsLUrOomlm+ZaRBlzJgKsHurMJ0wSbWZ6JuhzcB7c0Ii7eYpWYWSaIfLTgMvIrmNkWJeiUkZNwpQJuozNqmlnHlosWXES8tSULMbPsyNNtImZmH5ORfHPAmVk6IjsPVHbAmVk6chfVzHKqMJLBAWdmOZWNeHPAmdkmyEgDzgFnZmkp+/PBmZltjK+imlmu+SKDmeWTcjBluZnZxriLama55hacmeVWNuLNAWdmKQmoz0gLLitdaTOrIVJ5r9L70GBJD0p6XtJcSWcny3tLekDS/ORnr6Jtzpe0QNI8Sce0VacDzsxSUtn/taERODci9gQ+CZwhaQRwHjA9IoYB05PPJN+NBfYCxgBXJQ+nb5UDzsxSa48WXEQsjYgnk/fvAs8Dg4DjgcnJapOBE5L3xwNTImJtRCwEFgAHlTqGz8GZWSqF20TKPgfXV9Ksos+TImLSX+xT2hnYH3gMGBARS6EQgpL6J6sNAv5UtNniZFmrHHBmlk4ZrbMiDRExquTupO7AbcA/RsQ7JW5BSf0IUwecmaXWXkO1JHWmEG43RcTtyeJlkgYmrbeBwPJk+WJgcNHmOwJLStbZLlWaWYdRmPCyvFfJ/RSaatcBz0fEL4q+mgaMS96PA+4sWj5WUldJQ4FhwOOljuEWnJmlVsYV0nKMBv4OmCPpqWTZBcClwFRJ44FFwIkAETFX0lTgOQpXYM+IiKZSB3DAmVlq7dFDjYhHaH1QxEafyxwRE4GJ5R7DAVcBTU3NHPn3P2Vg/+245bLTuHTS3dzwh/+jT8/uAPzLGZ/nM6P3qnKVHdvTd/6Q1e+tpam5mcbGZo4a91MAvvmVw/nmVw6jsamZBx55louuuJPBA3vz2NTvs2BR4VTQrDmvcM6lU6pZftW1Uwuu4ioWcJKuB/4GWB4Re1fqOLXo6ikPMnzoAN5d88GHy0476Uj+4e8+XcWqbEPHnfpL3np7zYefD/3EMD57+D4cetJPWLe+kb69un/43SuvN3DYyZdWo8ya03IOLgsqeZHhtxTuNu5QXl+2kvsfmcvfH39ItUuxlE750qe4fPIDrFvfCEDDytVVrqhGSdSV+aq2igVcRMwE3qrU/mvVBb+4jR+edQJ1G/wv7te3zmT0SZdw5sU3suqd96pUnbWICG6/8kwevOG7jPvCaAB226k/B4/clQd+80/cdc3Z7D9iyIfrD9mhDw/d+D3uuuZsDh65a7XKrhkq81VtVT8HJ2kCMAFg8JAhbaxd2+59eA59e/Vg5J5DeGT2ix8uP+VLn+I7449FgolX38X3L7+dKy/8WhUrtTHfuIw3Gt6mb6/u3HHlmcx/5Q061dfRs8c2/PXXf8YBI3biN5ecwsgTfsCyhnfY57gLWfn2GvbbYzA3/WwCB//txI+dguhIsvRc1KrfBxcRkyJiVESM6te3X7XL2SyPPf0y9z48h30/fyHjL/gNDz/xIhP+ZTL9+2xLfX0ddXV1jDthNLPnvlrtUju8NxreBgrd0LtmPMMBe+3M68tX8ccHnwbgyedepTmCPj27s259IyuTc3VPv/AaCxc3sOuQ/q3uuyPISguu6gGXJxedeTxz7/4xz0y7mOsu+TqfOnA4k3407sN/TAB3zXiaPXcdWMUqbZututB9m64fvj/qk3vw/EtLuGfGMxx24HAAdh3Sny6dO7Fi1Wr69Oz+4SmHnQb1YZfB/Xjl9Yaq1V8TMpJwVe+idgQX/fsfmPPiYiQxZGBvLrvgpGqX1KH169ODG3/6TQDqO9Vz272zmP7o83TuVM+VF57M/025gHXrmzjtB78D4JD9d+P8Uz9HU2MTTc3BuZdO6fDnUbPSRVVEybGqm75j6WbgCKAvsAy4KCKuK7XNJz4xKv73sVmlVrEa0+vAM6tdgqWwdt5Umt9bvlnptOc++8cNd84oa92Ddu05u63B9pVUsRZcRLiZYpZX2WjAuYtqZukUTq9lI+EccGaWTrr54KrKAWdmqWUk3xxwZpaW/OBnM8uvjOSbA87M0qmRe3jL4oAzs/QyknAOODNLzbeJmFlu+RycmeWT74MzszxzF9XMckm4BWdmOZaRfHPAmdkmyEjCOeDMLLWsTHjpgDOz1LIRbw44M9sUGUk4B5yZpeIJL80sv3yjr5nlWUbyzQFnZml5wkszy7GM5JsDzszSydKEl3XVLsDMMkhlvtrajXS9pOWSni1a1lvSA5LmJz97FX13vqQFkuZJOqat/TvgzCw1lflfGX4LjNlg2XnA9IgYBkxPPiNpBDAW2CvZ5ipJ9aV27oAzs9Sk8l5tiYiZwFsbLD4emJy8nwycULR8SkSsjYiFwALgoFL79zk4M0tHUFf+Sbi+kmYVfZ4UEZPa2GZARCwFiIilkvonywcBfypab3GyrFUOODPbBGUnXENEjKrgQaPUBu6imlkqLRNetkcXtRXLJA0ESH4uT5YvBgYXrbcjsKTUjhxwZpZaO11Ebc00YFzyfhxwZ9HysZK6ShoKDAMeL7Ujd1HNLLX2utFX0s3AERTO1S0GLgIuBaZKGg8sAk4EiIi5kqYCzwGNwBkR0VRq/w44M0utvYZqRcRJrXx1dCvrTwQmlrt/B5yZpZaVkQwOODNLZTMvIGxRDjgzS80TXppZfmUj3xxwZpZeRvLNAWdmacmPDTSzfGoZyZAFHslgZrnlFpyZpZaVFpwDzsxS820iZpZPvtHXzPIqSxcZHHBmlpq7qGaWW27BmVluZSTfHHBmtgkyknAOODNLRZCZoVqKKPlQmi1K0pvAq9WuowL6Ag3VLsJSyevf2U4R0W9zdiDpXgp/PuVoiIgNH+y8xdRUwOWVpFnt+Og02wL8d5YPHotqZrnlgDOz3HLAbRmTql2Apea/sxzwOTgzyy234MwstxxwZpZbDrgKkjRG0jxJCySdV+16rG2Srpe0XNKz1a7FNp8DrkIk1QO/Ao4FRgAnSRpR3aqsDL8FqnZjqrUvB1zlHAQsiIiXI2IdMAU4vso1WRsiYibwVrXrsPbhgKucQcBrRZ8XJ8vMbAtxwFXOxkYj+54csy3IAVc5i4HBRZ93BJZUqRazDskBVzlPAMMkDZXUBRgLTKtyTWYdigOuQiKiETgTuA94HpgaEXOrW5W1RdLNwKPA7pIWSxpf7Zps03molpnllltwZpZbDjgzyy0HnJnllgPOzHLLAWdmueWAyxBJTZKekvSspFslbbMZ+/qtpC8n768tNRGApCMkHbIJx3hF0l88fam15RusszrlsX4g6Z/S1mj55oDLlvcjYmRE7A2sA04t/jKZwSS1iPhGRDxXYpUjgNQBZ1ZtDrjsehjYLWldPSjp98AcSfWS/k3SE5KekfQtABVcKek5SXcD/Vt2JGmGpFHJ+zGSnpT0tKTpknamEKTfTlqPn5LUT9JtyTGekDQ62baPpPsl/VnSNZTx/HNJf5A0W9JcSRM2+O7nSS3TJfVLlu0q6d5km4cl7dEuf5qWS36yfQZJ6kRhnrl7k0UHAXtHxMIkJN6OiAMldQX+V9L9wP7A7sA+wADgOeD6DfbbD/g1cFiyr94R8Zakq4HVEfGzZL3fA5dFxCOShlAYrbEncBHwSERcLOlzwMcCqxWnJMfYGnhC0m0RsQLoBjwZEedKujDZ95kUHgZzakTMl/RXwFXAUZvwx2gdgAMuW7aW9FTy/mHgOgpdx8cjYmGy/DPAvi3n14DtgGHAYcDNEdEELJH0PxvZ/yeBmS37iojW5kX7NDBC+rCBtq2kHskxvphse7eklWX8TmdJ+kLyfnBS6wqgGbglWX4jcLuk7snve2vRsbuWcQzroBxw2fJ+RIwsXpD8Q19TvAj4h4i4b4P1Pkvb0zWpjHWgcGrj4Ih4fyO1lD32T9IRFMLy4Ih4T9IMYKtWVo/kuKs2/DMwa43PweXPfcBpkjoDSBouqRswExibnKMbCBy5kW0fBQ6XNDTZtney/F2gR9F691PoLpKsNzJ5OxM4OVl2LNCrjVq3A1Ym4bYHhRZkizqgpRX6VQpd33eAhZJOTI4hSfu1cQzrwBxw+XMthfNrTyYPTrmGQkv9DmA+MAf4D+ChDTeMiDcpnDe7XdLTfNRF/CPwhZaLDMBZwKjkIsZzfHQ194fAYZKepNBVXtRGrfcCnSQ9A/wI+FPRd2uAvSTNpnCO7eJk+cnA+KS+uXgaeCvBs4mYWW65BWdmueWAM7PccsCZWW454MwstxxwZpZbDjgzyy0HnJnl1v8DcLqvLBK7opwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds_13 = pipe_13.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_13).ravel()\n",
    "cm_13 = tn, fp, fn, tp \n",
    "get_evaluation_metrics('Model NB_1.3', cm_13, preds_13)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "spec_13 = tn / (tn + fp)\n",
    "\n",
    "# visualizing confusion matrix\n",
    "plot_confusion_matrix(pipe_13, X_test, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model NB_1.4 - Optimizing Model_1.3 using GridSearchCV <a class=\"anchor\" id=\"nb_1.4\"></a>\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# Minimum number of documents needed to include token: 2, 3\n",
    "# Maximum number of documents needed to include token: 90%, 95%\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_params = {\n",
    "    'tvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'tvec__min_df': [2, 3],\n",
    "    'tvec__max_df': [.9, .95],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words=('english',\n",
       "                                                                    'onion',\n",
       "                                                                    'topical',\n",
       "                                                                    'ho'))),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000, 5000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "tvec_gs = GridSearchCV(pipe_13, # what object are we optimizing?\n",
    "                       param_grid=pipe_params, # what parameters values are we searching?\n",
    "                       cv=5) # 5-fold cross-validation.\n",
    "\n",
    "# Fit GridSearch to training data.\n",
    "tvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NB_1.4\n",
      "------------\n",
      "Best Parameters: {'tvec__max_df': 0.9, 'tvec__max_features': 4000, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 1)}\n",
      "Best train score: 0.8972\n"
     ]
    }
   ],
   "source": [
    "get_gs_metrics('Model NB_1.4', tvec_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NB_1.4\n",
      "------------\n",
      "Training score: 0.9597\n",
      "Testing score: 0.8896\n"
     ]
    }
   ],
   "source": [
    "get_scores('Model NB_1.4', tvec_gs)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "train_score_14 = tvec_gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NB_1.4\n",
      "------------\n",
      "True Negatives: 373\n",
      "False Positives: 68\n",
      "False Negatives: 48\n",
      "True Positives: 562\n",
      "\n",
      "Accuracy: 0.8896\n",
      "Specificity: 0.8458\n",
      "Sensitivity: 0.9213\n",
      "Precision: 0.8921\n",
      "F1 score: 0.9065\n",
      "ROC AUC score: 0.8836\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds_14 = tvec_gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_14).ravel()\n",
    "cm_14 = tn, fp, fn, tp \n",
    "get_evaluation_metrics('Model NB_1.4', cm_14, preds_14)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "spec_14 = tn / (tn + fp)\n",
    "\n",
    "# visualizing confusion matrix\n",
    "plot_confusion_matrix(tvec_gs, X_test, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary & Evaluation for Naive Bayes Modelling <a class=\"anchor\" id=\"nb_summary\"></a>\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list of dict\n",
    "dict_nb = [{'Model': 'NB_1.1', \n",
    "            'cvec': 1, 'tvec': 0, 'gs': 0,\n",
    "            'Train Score': train_score_11, \n",
    "            'Test Score': accuracy_score(y_test, preds_11),\n",
    "            'Precision': precision_score(y_test, preds_11), \n",
    "            'Specificity': spec_11,\n",
    "            'Recall': recall_score(y_test, preds_11),\n",
    "            'F1 Score': f1_score(y_test, preds_11), \n",
    "            'ROC AUC Score': roc_auc_score(y_test, preds_11),},\n",
    "           {'Model': 'NB_1.2', \n",
    "            'cvec': 1, 'tvec': 0, 'gs': 1,\n",
    "            'Train Score': train_score_12, \n",
    "            'Test Score': accuracy_score(y_test, preds_13),\n",
    "            'Precision': precision_score(y_test, preds_13), \n",
    "            'Specificity': spec_12,\n",
    "            'Recall': recall_score(y_test, preds_13),\n",
    "            'F1 Score': f1_score(y_test, preds_13), \n",
    "            'ROC AUC Score': roc_auc_score(y_test, preds_13),},\n",
    "           {'Model': 'NB_1.3', \n",
    "            'cvec': 0, 'tvec': 1, 'gs': 0,\n",
    "            'Train Score': train_score_13, \n",
    "            'Test Score': accuracy_score(y_test, preds_13),\n",
    "            'Precision': precision_score(y_test, preds_13), \n",
    "            'Specificity': spec_13,\n",
    "            'Recall': recall_score(y_test, preds_13),\n",
    "            'F1 Score': f1_score(y_test, preds_13), \n",
    "            'ROC AUC Score': roc_auc_score(y_test, preds_13),},\n",
    "           {'Model': 'NB_1.4', \n",
    "            'cvec': 0, 'tvec': 1, 'gs': 1,\n",
    "            'Train Score': train_score_14, \n",
    "            'Test Score': accuracy_score(y_test, preds_14),\n",
    "            'Precision': precision_score(y_test, preds_14), \n",
    "            'Specificity': spec_14,\n",
    "            'Recall': recall_score(y_test, preds_14),\n",
    "            'F1 Score': f1_score(y_test, preds_14), \n",
    "            'ROC AUC Score': roc_auc_score(y_test, preds_14),}\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>cvec</th>\n",
       "      <th>tvec</th>\n",
       "      <th>gs</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.9039</td>\n",
       "      <td>0.9306</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.9016</td>\n",
       "      <td>0.9159</td>\n",
       "      <td>0.9043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB_1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.8991</td>\n",
       "      <td>0.9026</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.8940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB_1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>0.8991</td>\n",
       "      <td>0.9026</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.8940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB_1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9597</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8921</td>\n",
       "      <td>0.8458</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.9065</td>\n",
       "      <td>0.8836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  cvec  tvec  gs  Train Score  Test Score  Precision  Specificity  \\\n",
       "0  NB_1.1     1     0   0       0.9772      0.9039     0.9306       0.9070   \n",
       "1  NB_1.2     1     0   1       0.9588      0.8991     0.9026       0.8934   \n",
       "2  NB_1.3     0     1   0       0.9753      0.8991     0.9026       0.8617   \n",
       "3  NB_1.4     0     1   1       0.9597      0.8896     0.8921       0.8458   \n",
       "\n",
       "   Recall  F1 Score  ROC AUC Score  \n",
       "0  0.9016    0.9159         0.9043  \n",
       "1  0.9262    0.9142         0.8940  \n",
       "2  0.9262    0.9142         0.8940  \n",
       "3  0.9213    0.9065         0.8836  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nb = pd.DataFrame(dict_nb)\n",
    "df_nb.round(4) # rounding off values to 4 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Observations for using Multinomial Naive Bayes as the Satirical News Classification Model\n",
    "* All models tend to be overfitted to the training set.\n",
    "* Using Count Vectorizer as a transformer generally yields better scores as compared to using TD-IDF Vectorizer with some exceptions e.g. `Recall`\n",
    "* NB_1.2 and NB_1.3 has the highest `Recall` scores, meaning that the chances of getting false negatives are lower compared to the other two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression <a class=\"anchor\" id=\"logreg\"></a>\n",
    "---\n",
    "[Back to top!](#toc)\n",
    "\n",
    "A total of 4 models will be trained using Logistic Regression as an estimator:\n",
    "* Model LR_2.1 - Using CountVectorizer and Logistic Regression\n",
    "* Model LR_2.2 - Optimizing Model LR_2.1 using GridSearchCV\n",
    "* Model LR_2.3 - Using TF-IDF Vectorizer and Logistic Regression\n",
    "* Model LR_2.4 - Optimizing Model LR_2.3 using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model LR_2.1 - Using CountVectorizer and Logistic Regression <a class=\"anchor\" id=\"lr_2.1\"></a>\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec',\n",
       "   CountVectorizer(stop_words=('english', 'onion', 'topical', 'ho'))),\n",
       "  ('lr', LogisticRegression())],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(stop_words=('english', 'onion', 'topical', 'ho')),\n",
       " 'lr': LogisticRegression(),\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': ('english', 'onion', 'topical', 'ho'),\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': None,\n",
       " 'cvec__vocabulary': None,\n",
       " 'lr__C': 1.0,\n",
       " 'lr__class_weight': None,\n",
       " 'lr__dual': False,\n",
       " 'lr__fit_intercept': True,\n",
       " 'lr__intercept_scaling': 1,\n",
       " 'lr__l1_ratio': None,\n",
       " 'lr__max_iter': 100,\n",
       " 'lr__multi_class': 'auto',\n",
       " 'lr__n_jobs': None,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__random_state': None,\n",
       " 'lr__solver': 'lbfgs',\n",
       " 'lr__tol': 0.0001,\n",
       " 'lr__verbose': 0,\n",
       " 'lr__warm_start': False}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redefining training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Setting up pipeline for model 2.1\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Logistic Regression (estimator)\n",
    "pipe_21 = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=('english', 'onion', 'topical', 'ho'))),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fitting the pipeline\n",
    "pipe_21.fit(X_train, y_train)\n",
    "pipe_21.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LR_2.1\n",
      "------------\n",
      "Training score: 0.9965\n",
      "Testing score: 0.9049\n"
     ]
    }
   ],
   "source": [
    "get_scores('Model LR_2.1', pipe_21)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "train_score_21 = pipe_21.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LR_2.1\n",
      "------------\n",
      "True Negatives: 377\n",
      "False Positives: 64\n",
      "False Negatives: 36\n",
      "True Positives: 574\n",
      "\n",
      "Accuracy: 0.9049\n",
      "Specificity: 0.8549\n",
      "Sensitivity: 0.941\n",
      "Precision: 0.8997\n",
      "F1 score: 0.9199\n",
      "ROC AUC score: 0.8979\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds_21 = pipe_21.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_21).ravel()\n",
    "cm_21 = tn, fp, fn, tp \n",
    "get_evaluation_metrics('Model LR_2.1', cm_21, preds_21)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "spec_21 = tn / (tn + fp)\n",
    "\n",
    "# visualizing confusion matrix\n",
    "plot_confusion_matrix(pipe_21, X_test, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model LR_2.2 - Optimizing Model LR_2.1 using GridSearchCV  <a class=\"anchor\" id=\"lr_2.2\"></a>\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# Minimum number of documents needed to include token: 2, 3\n",
    "# Maximum number of documents needed to include token: 90%, 95%\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words=('english',\n",
       "                                                                    'onion',\n",
       "                                                                    'topical',\n",
       "                                                                    'ho'))),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "cvec_gs = GridSearchCV(pipe_21, # what object are we optimizing?\n",
    "                       param_grid=pipe_params, # what parameters values are we searching?\n",
    "                       cv=5) # 5-fold cross-validation.\n",
    "\n",
    "# Fit GridSearch to training data.\n",
    "cvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LR_2.2\n",
      "------------\n",
      "Best Parameters: {'cvec__max_df': 0.9, 'cvec__max_features': 4000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1)}\n",
      "Best train score: 0.89\n"
     ]
    }
   ],
   "source": [
    "get_gs_metrics('Model LR_2.2', cvec_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LR_2.2\n",
      "------------\n",
      "Training score: 0.9899\n",
      "Testing score: 0.8991\n"
     ]
    }
   ],
   "source": [
    "get_scores('Model LR_2.2', cvec_gs)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "train_score_22 = cvec_gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LR_2.2\n",
      "------------\n",
      "True Negatives: 376\n",
      "False Positives: 65\n",
      "False Negatives: 41\n",
      "True Positives: 569\n",
      "\n",
      "Accuracy: 0.8991\n",
      "Specificity: 0.8526\n",
      "Sensitivity: 0.9328\n",
      "Precision: 0.8975\n",
      "F1 score: 0.9148\n",
      "ROC AUC score: 0.8927\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds_22 = cvec_gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_22).ravel()\n",
    "cm_22 = tn, fp, fn, tp \n",
    "get_evaluation_metrics('Model LR_2.2', cm_22, preds_22)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "spec_22 = tn / (tn + fp)\n",
    "\n",
    "# visualizing confusion matrix\n",
    "plot_confusion_matrix(cvec_gs, X_test, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model LR_2.3 - Using TF-IDF Vectorizer and Logistic Regression <a class=\"anchor\" id=\"lr_2.3\"></a>\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tvec',\n",
       "   TfidfVectorizer(stop_words=('english', 'onion', 'topical', 'ho'))),\n",
       "  ('lr', LogisticRegression())],\n",
       " 'verbose': False,\n",
       " 'tvec': TfidfVectorizer(stop_words=('english', 'onion', 'topical', 'ho')),\n",
       " 'lr': LogisticRegression(),\n",
       " 'tvec__analyzer': 'word',\n",
       " 'tvec__binary': False,\n",
       " 'tvec__decode_error': 'strict',\n",
       " 'tvec__dtype': numpy.float64,\n",
       " 'tvec__encoding': 'utf-8',\n",
       " 'tvec__input': 'content',\n",
       " 'tvec__lowercase': True,\n",
       " 'tvec__max_df': 1.0,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__norm': 'l2',\n",
       " 'tvec__preprocessor': None,\n",
       " 'tvec__smooth_idf': True,\n",
       " 'tvec__stop_words': ('english', 'onion', 'topical', 'ho'),\n",
       " 'tvec__strip_accents': None,\n",
       " 'tvec__sublinear_tf': False,\n",
       " 'tvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tvec__tokenizer': None,\n",
       " 'tvec__use_idf': True,\n",
       " 'tvec__vocabulary': None,\n",
       " 'lr__C': 1.0,\n",
       " 'lr__class_weight': None,\n",
       " 'lr__dual': False,\n",
       " 'lr__fit_intercept': True,\n",
       " 'lr__intercept_scaling': 1,\n",
       " 'lr__l1_ratio': None,\n",
       " 'lr__max_iter': 100,\n",
       " 'lr__multi_class': 'auto',\n",
       " 'lr__n_jobs': None,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__random_state': None,\n",
       " 'lr__solver': 'lbfgs',\n",
       " 'lr__tol': 0.0001,\n",
       " 'lr__verbose': 0,\n",
       " 'lr__warm_start': False}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redefining training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Setting up pipeline for model 2.1\n",
    "# 1. TF-IDF Vectorizer (transformer)\n",
    "# 2. Logistic Regression (estimator)\n",
    "pipe_23 = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(stop_words=('english', 'onion', 'topical', 'ho'))),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fitting the pipeline\n",
    "pipe_23.fit(X_train, y_train)\n",
    "pipe_23.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LR_2.3\n",
      "------------\n",
      "Training score: 0.9623\n",
      "Testing score: 0.8915\n"
     ]
    }
   ],
   "source": [
    "get_scores('Model LR_2.3', pipe_23)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "train_score_23 = pipe_23.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LR_2.3\n",
      "------------\n",
      "True Negatives: 353\n",
      "False Positives: 88\n",
      "False Negatives: 26\n",
      "True Positives: 584\n",
      "\n",
      "Accuracy: 0.8915\n",
      "Specificity: 0.8005\n",
      "Sensitivity: 0.9574\n",
      "Precision: 0.869\n",
      "F1 score: 0.9111\n",
      "ROC AUC score: 0.8789\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds_23 = pipe_23.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_23).ravel()\n",
    "cm_23 = tn, fp, fn, tp \n",
    "get_evaluation_metrics('Model LR_2.3', cm_23, preds_23)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "spec_23 = tn / (tn + fp)\n",
    "\n",
    "# visualizing confusion matrix\n",
    "plot_confusion_matrix(pipe_23, X_test, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model LR_2.4 - Optimizing Model LR_2.3 using GridSearchCV <a class=\"anchor\" id=\"lr_2.4\"></a>\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# Minimum number of documents needed to include token: 2, 3\n",
    "# Maximum number of documents needed to include token: 90%, 95%\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_params = {\n",
    "    'tvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'tvec__min_df': [2, 3],\n",
    "    'tvec__max_df': [.9, .95],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words=('english',\n",
       "                                                                    'onion',\n",
       "                                                                    'topical',\n",
       "                                                                    'ho'))),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             param_grid={'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000, 5000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "tvec_gs = GridSearchCV(pipe_23, # what object are we optimizing?\n",
    "                       param_grid=pipe_params, # what parameters values are we searching?\n",
    "                       cv=5) # 5-fold cross-validation.\n",
    "\n",
    "# Fit GridSearch to training data.\n",
    "tvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LR_2.4\n",
      "------------\n",
      "Best Parameters: {'tvec__max_df': 0.9, 'tvec__max_features': 4000, 'tvec__min_df': 3, 'tvec__ngram_range': (1, 2)}\n",
      "Best train score: 0.8877\n"
     ]
    }
   ],
   "source": [
    "get_gs_metrics('Model LR_2.4', tvec_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LR_2.4\n",
      "------------\n",
      "Training score: 0.9559\n",
      "Testing score: 0.8868\n"
     ]
    }
   ],
   "source": [
    "get_scores('Model LR_2.4', tvec_gs)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "train_score_24 = tvec_gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LR_2.4\n",
      "------------\n",
      "True Negatives: 357\n",
      "False Positives: 84\n",
      "False Negatives: 35\n",
      "True Positives: 575\n",
      "\n",
      "Accuracy: 0.8868\n",
      "Specificity: 0.8095\n",
      "Sensitivity: 0.9426\n",
      "Precision: 0.8725\n",
      "F1 score: 0.9062\n",
      "ROC AUC score: 0.8761\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds_24 = tvec_gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_24).ravel()\n",
    "cm_24 = tn, fp, fn, tp \n",
    "get_evaluation_metrics('Model LR_2.4', cm_24, preds_24)\n",
    "\n",
    "# keeping variable for summary input later\n",
    "spec_24 = tn / (tn + fp)\n",
    "\n",
    "# visualizing confusion matrix\n",
    "plot_confusion_matrix(tvec_gs, X_test, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary & Evaluation for Logistic Regression Modelling <a class=\"anchor\" id=\"lr_summary\"></a>\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dict\n",
    "dict_lr = [{'Model': 'LR_2.1', \n",
    "            'cvec': 1, 'tvec': 0, 'gs': 0,\n",
    "            'Train Score': train_score_21, \n",
    "            'Test Score': accuracy_score(y_test, preds_21),\n",
    "            'Precision': precision_score(y_test, preds_21), \n",
    "            'Specificity': spec_21,\n",
    "            'Recall': recall_score(y_test, preds_21),\n",
    "            'F1 Score': f1_score(y_test, preds_21), \n",
    "            'ROC AUC Score': roc_auc_score(y_test, preds_21),},\n",
    "           {'Model': 'LR_2.2', \n",
    "            'cvec': 1, 'tvec': 0, 'gs': 1,\n",
    "            'Train Score': train_score_22, \n",
    "            'Test Score': accuracy_score(y_test, preds_22),\n",
    "            'Precision': precision_score(y_test, preds_22), \n",
    "            'Specificity': spec_22,\n",
    "            'Recall': recall_score(y_test, preds_22),\n",
    "            'F1 Score': f1_score(y_test, preds_22), \n",
    "            'ROC AUC Score': roc_auc_score(y_test, preds_22),},\n",
    "           {'Model': 'LR_2.3', \n",
    "            'cvec': 0, 'tvec': 1, 'gs': 0,\n",
    "            'Train Score': train_score_23, \n",
    "            'Test Score': accuracy_score(y_test, preds_23),\n",
    "            'Precision': precision_score(y_test, preds_23), \n",
    "            'Specificity': spec_23,\n",
    "            'Recall': recall_score(y_test, preds_23),\n",
    "            'F1 Score': f1_score(y_test, preds_23), \n",
    "            'ROC AUC Score': roc_auc_score(y_test, preds_23),},\n",
    "           {'Model': 'LR_2.4', \n",
    "            'cvec': 0, 'tvec': 1, 'gs': 1,\n",
    "            'Train Score': train_score_24, \n",
    "            'Test Score': accuracy_score(y_test, preds_24),\n",
    "            'Precision': precision_score(y_test, preds_24), \n",
    "            'Specificity': spec_24,\n",
    "            'Recall': recall_score(y_test, preds_24),\n",
    "            'F1 Score': f1_score(y_test, preds_24), \n",
    "            'ROC AUC Score': roc_auc_score(y_test, preds_24),}\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>cvec</th>\n",
       "      <th>tvec</th>\n",
       "      <th>gs</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>0.9049</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>0.8549</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.9199</td>\n",
       "      <td>0.8979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR_2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>0.8991</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>0.8526</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.9148</td>\n",
       "      <td>0.8927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR_2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9623</td>\n",
       "      <td>0.8915</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.9574</td>\n",
       "      <td>0.9111</td>\n",
       "      <td>0.8789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR_2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9559</td>\n",
       "      <td>0.8868</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.9426</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>0.8761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  cvec  tvec  gs  Train Score  Test Score  Precision  Specificity  \\\n",
       "0  LR_2.1     1     0   0       0.9965      0.9049     0.8997       0.8549   \n",
       "1  LR_2.2     1     0   1       0.9899      0.8991     0.8975       0.8526   \n",
       "2  LR_2.3     0     1   0       0.9623      0.8915     0.8690       0.8005   \n",
       "3  LR_2.4     0     1   1       0.9559      0.8868     0.8725       0.8095   \n",
       "\n",
       "   Recall  F1 Score  ROC AUC Score  \n",
       "0  0.9410    0.9199         0.8979  \n",
       "1  0.9328    0.9148         0.8927  \n",
       "2  0.9574    0.9111         0.8789  \n",
       "3  0.9426    0.9062         0.8761  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr = pd.DataFrame(dict_lr)\n",
    "df_lr.round(4) # rounding off values to 4 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Observations for using Logistic Regression as the Satirical News Classification Model\n",
    "* All models tend to be overfitted to the training set.\n",
    "* Using Count Vectorizer as a transformer generally yields better scores as compared to using TD-IDF Vectorizer with some exceptions e.g. `Recall`\n",
    "* LR_2.3 has the highest `Recall` score, meaning that the chances of getting false negatives are lower compared to the other three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation and Conceptual Understanding\n",
    "\n",
    "#     Does the student accurately identify and explain the baseline score?\n",
    "#     Does the student select and use metrics relevant to the problem objective?\n",
    "#     Does the student interpret the results of their model for purposes of inference?\n",
    "#     Is domain knowledge demonstrated when interpreting results?\n",
    "#     Does the student provide appropriate interpretation with regards to descriptive and inferential statistics?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Scores across all Models <a class=\"anchor\" id=\"comparison\"></a>\n",
    "---\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case of a classification model where we are predicting posts that contains satirical news, we probably want to find some combination of sensitivity and Specificity. \n",
    "- Focusing only on sensitivity means we minimize false negatives. This means that there will be less news that we incorrectly predict as non-satire, but more news we incorrectly predict to be satire.\n",
    "- Focusing only on specificity means we minimize false positives. This means that there will be less news that we incorrectly predict as satire, but more news we incorrectly predict to be non-satire.\n",
    "\n",
    "Sensitivity and specificity are not equally important in this case though. Sensitivity is more important as it is better to tell people that non-satirical news are satire as compared to tell people that satirical news are not satire, reducing the chances of misinformation. \n",
    "\n",
    "While focusing on sensitivity, we must also not let specificity suffer too much. Lower specificity will result in the classification model telling us that most non-satirical news are satire, which might be unethical as it will mislead the masses to disbelieve news that may be true and relevant.\n",
    "\n",
    "Hence, in this classification model, the evaluation metrics optimized will be:\n",
    "1) `Recall`, as it's better than optimizing `Specificity`. <br/>\n",
    "2) Try to optimize `F1 Score`, a combination of `Recall` and `Specificity`. This will ensure that our specificity does not suffer too much as we are optimizing sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>cvec</th>\n",
       "      <th>tvec</th>\n",
       "      <th>gs</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC Score</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR_2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9623</td>\n",
       "      <td>0.8915</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.9574</td>\n",
       "      <td>0.9111</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>0.0707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR_2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9559</td>\n",
       "      <td>0.8868</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.9426</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>0.8761</td>\n",
       "      <td>0.0691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR_2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>0.9049</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>0.8549</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.9199</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.0917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR_2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>0.8991</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>0.8526</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.9148</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.0907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB_1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.8991</td>\n",
       "      <td>0.9026</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>0.0596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB_1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>0.8991</td>\n",
       "      <td>0.9026</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>0.0761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB_1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9597</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8921</td>\n",
       "      <td>0.8458</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.9065</td>\n",
       "      <td>0.8836</td>\n",
       "      <td>0.0701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB_1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.9039</td>\n",
       "      <td>0.9306</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.9016</td>\n",
       "      <td>0.9159</td>\n",
       "      <td>0.9043</td>\n",
       "      <td>0.0733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Null Model</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  cvec  tvec  gs  Train Score  Test Score  Precision  \\\n",
       "7      LR_2.3     0     1   0       0.9623      0.8915     0.8690   \n",
       "8      LR_2.4     0     1   1       0.9559      0.8868     0.8725   \n",
       "5      LR_2.1     1     0   0       0.9965      0.9049     0.8997   \n",
       "6      LR_2.2     1     0   1       0.9899      0.8991     0.8975   \n",
       "2      NB_1.2     1     0   1       0.9588      0.8991     0.9026   \n",
       "3      NB_1.3     0     1   0       0.9753      0.8991     0.9026   \n",
       "4      NB_1.4     0     1   1       0.9597      0.8896     0.8921   \n",
       "1      NB_1.1     1     0   0       0.9772      0.9039     0.9306   \n",
       "0  Null Model     0     0   0          NaN      0.5804        NaN   \n",
       "\n",
       "   Specificity  Recall  F1 Score  ROC AUC Score  Difference  \n",
       "7       0.8005  0.9574    0.9111         0.8789      0.0707  \n",
       "8       0.8095  0.9426    0.9062         0.8761      0.0691  \n",
       "5       0.8549  0.9410    0.9199         0.8979      0.0917  \n",
       "6       0.8526  0.9328    0.9148         0.8927      0.0907  \n",
       "2       0.8934  0.9262    0.9142         0.8940      0.0596  \n",
       "3       0.8617  0.9262    0.9142         0.8940      0.0761  \n",
       "4       0.8458  0.9213    0.9065         0.8836      0.0701  \n",
       "1       0.9070  0.9016    0.9159         0.9043      0.0733  \n",
       "0          NaN     NaN       NaN            NaN         NaN  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models = [df_null, df_nb, df_lr]\n",
    "df_summary = pd.concat(all_models, ignore_index=True)\n",
    "\n",
    "# to estimate the extent of overfitting of model to training set across all models\n",
    "df_summary[['Difference']] = df_summary['Train Score'] - df_summary['Test Score']\n",
    "df_summary.round(4).sort_values(by=['Recall'], ascending=False)\n",
    "#df_summary.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking across the scores of all classification models trained and tested:\n",
    "\n",
    "* All other models fared better than the baseline model. \n",
    "* All models have the tendency of overfitting to the training data as seen from `Difference`, with the highest being LR_2.1 and lowest being NB_1.2. This means that NB_1.2 has the best ability to generalize to unseen data among all models.\n",
    "* All the `Test Score` are in the same range of values (approximately 0.88 to 0.91).\n",
    "* Models using Logistic Regression generally has better `Recall` scores compared to Multinomial Naive Bayes.\n",
    "* LR_2.1 scored the highest for `Test Score` aka accuracy, but it is the most overfitted model among the others.\n",
    "* LR_2.3 scored the highest for `Recall`, but has a lower `F1 Score` compared to the rest of the models. \n",
    "* LR_2.1 scored the highest for `F1 Score` while having a relatively high score for `Recall` among all models.\n",
    "* While the `ROC AUC Score` is higher for LR_2.1 compared to LR_2.3, the difference is relatively small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions <a class=\"anchor\" id=\"conclusions\"></a>\n",
    "---\n",
    "[Back to top!](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations for the Satirical News Classifier\n",
    "\n",
    "LR_2.3 will be the most suitable model for this satirical news classifier based on the summary of scores shown above. It scores the best in `Recall`, which is the evaluation metric that should be optimized in order to reduce false negatives. The `F1 Score` is only slightly compromised (negligible difference of 0.0088) as a result of optimizing `Recall`, which is still within acceptable range. Similarly for `ROC AUC Score` where LR_2.3 scored the second lowest among all the other models, it is still within acceptable range.\n",
    "\n",
    "Hence, I would recommend LR_2.3 to be used as the satirical news classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Development for the Satirical News Classification Model\n",
    "\n",
    "1) Other classification models that can be trained and evaluated:\n",
    "- K-Nearest Neighbours\n",
    "- Decision Tree\n",
    "- Bagged Decision Trees\n",
    "- Random Forest\n",
    "- Support Vector Regressor \n",
    "<br/>\n",
    "\n",
    "2) Further hyperparameter tuning that can be done:\n",
    "- Using RandomizedSearchCV instead of only GridSearchCV to explore higher numbers of different hyperparameters\n",
    "<br/>\n",
    "\n",
    "3) More in-depth model evaluation metrics that can be done:\n",
    "- Optimizing a custom metric that weighs `Recall` somewhat more importantly than `Specificity`.\n",
    "- Looking at my ROC curve and try to find a place where `Recall` is very high and 1 - `Specificity` is pretty low.\n",
    "\n",
    "4) To further increase the business value of this project for the clients, instead of scraping only the posts of the subreddit to determine whether it is satirical news, this classification model can also scrape the contents of the linked articles to further determine whether it belongs to satire. This will not only increase the sensitivity of the model, but also ensure that the title of the post will not be able to mislead and by-pass the classification model if the linked article is actually a satire piece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
